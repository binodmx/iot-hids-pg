{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Is Intel GPU available? Yes\n",
      "2. Brand, Version info of GPU: Intel(R) OpenCL Graphics\n",
      "3. Specs of GPU: \n",
      "\t- Device 1: \n",
      "\t  - Name: Intel(R) Iris(R) Xe Graphics\n",
      "\t  - Type: ALL | GPU\n",
      "\t  - Compute Units: 80\n",
      "\t  - Global Memory: 6483 MB\n",
      "\t  - Local Memory: 64 KB\n",
      "\t  - Max Clock Frequency: 1200 MHz\n",
      "\t  - Max Work Group Size: 512\n",
      "\t  - Max Work Item Sizes: [512, 512, 512]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyopencl as cl\n",
    "\n",
    "def check_intel_gpu():\n",
    "    try:\n",
    "        platforms = cl.get_platforms()\n",
    "        intel_platforms = [platform for platform in platforms if 'Intel' in platform.name]\n",
    "        if not intel_platforms:\n",
    "            print(\"1. Is Intel GPU available? No\")\n",
    "            return\n",
    "\n",
    "        print(\"1. Is Intel GPU available? Yes\")\n",
    "        \n",
    "        for platform in intel_platforms:\n",
    "            print(\"2. Brand, Version info of GPU: {}\".format(platform.name))\n",
    "            print(\"3. Specs of GPU: \")\n",
    "            devices = platform.get_devices()\n",
    "            for i, device in enumerate(devices):\n",
    "                print(\"\\t- Device {}: \".format(i+1))\n",
    "                print(\"\\t  - Name: {}\".format(device.name))\n",
    "                print(\"\\t  - Type: {}\".format(cl.device_type.to_string(device.type)))\n",
    "                print(\"\\t  - Compute Units: {}\".format(device.max_compute_units))\n",
    "                print(\"\\t  - Global Memory: {} MB\".format(device.global_mem_size // (1024 * 1024)))\n",
    "                print(\"\\t  - Local Memory: {} KB\".format(device.local_mem_size // 1024))\n",
    "                print(\"\\t  - Max Clock Frequency: {} MHz\".format(device.max_clock_frequency))\n",
    "                print(\"\\t  - Max Work Group Size: {}\".format(device.max_work_group_size))\n",
    "                print(\"\\t  - Max Work Item Sizes: {}\".format(device.max_work_item_sizes))\n",
    "                print()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "check_intel_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Is GPU available? No\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "\n",
    "def check_gpu():\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        if not gpus:\n",
    "            print(\"1. Is GPU available? No\")\n",
    "            return\n",
    "\n",
    "        print(\"1. Is GPU available? Yes\")\n",
    "        \n",
    "        for gpu in gpus:\n",
    "            print(\"2. Brand, Version info of GPU {}: {}\".format(gpu.id, gpu.name))\n",
    "            print(\"3. Specs of GPU {}: \".format(gpu.id))\n",
    "            print(\"\\t- Capacity: {} MB\".format(gpu.memoryTotal))\n",
    "            print(\"\\t- Memory Clock Rate: {} MHz\".format(gpu.memoryClock))\n",
    "            print(\"\\t- Memory Bus Width: {} bits\".format(gpu.memoryBusWidth))\n",
    "            print(\"\\t- Number of Cores: {}\".format(gpu.multiProcessorCount * gpu.coreCount))\n",
    "            print()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "check_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "def check_gpu():\n",
    "    try:\n",
    "        cuda.init()\n",
    "        device_count = cuda.Device.count()\n",
    "        if device_count == 0:\n",
    "            print(\"1. Is GPU available? No\")\n",
    "            return\n",
    "\n",
    "        print(\"1. Is GPU available? Yes\")\n",
    "        \n",
    "        for i in range(device_count):\n",
    "            device = cuda.Device(i)\n",
    "            print(\"2. Brand, Version info of GPU {}: {}\".format(i+1, device.name()))\n",
    "            print(\"3. Specs of GPU {}: \".format(i+1))\n",
    "            print(\"\\t- Capacity: {} MB\".format(device.total_memory() // (1024 * 1024)))\n",
    "            print(\"\\t- Memory Clock Rate: {} MHz\".format(device.get_attribute(cuda.device_attribute.MEMORY_CLOCK_RATE) / 1000))\n",
    "            print(\"\\t- Memory Bus Width: {} bits\".format(device.get_attribute(cuda.device_attribute.GLOBAL_MEMORY_BUS_WIDTH)))\n",
    "            print(\"\\t- Number of Cores: {}\".format(device.get_attribute(cuda.device_attribute.MULTIPROCESSOR_COUNT) * device.get_attribute(cuda.device_attribute.CORE_COUNT)))\n",
    "            print(\"\\t- Compute Capability: {}\".format(device.compute_capability()))\n",
    "            print(\"\\t- Driver Version: {}\".format(device.driver_version()))\n",
    "            print(\"\\t- CUDA Capability: {}.{}\".format(*device.get_attribute(cuda.device_attribute.COMPUTE_CAPABILITY_MAJOR), *device.get_attribute(cuda.device_attribute.COMPUTE_CAPABILITY_MINOR)))\n",
    "            print()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_gpu()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
