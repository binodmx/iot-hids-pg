{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+---------+--------+\n",
      "| Atack type   |   Total |   Train |   Test |\n",
      "+==============+=========+=========+========+\n",
      "| Normal       |    5000 |    4000 |   1000 |\n",
      "+--------------+---------+---------+--------+\n",
      "| Attack       |    5000 |    4000 |   1000 |\n",
      "+--------------+---------+---------+--------+\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Load dataset and split it into training and test set\n",
    "################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "# Load dateset\n",
    "df_train = pd.read_csv(os.getcwd() + f'/data/sample-{sample_size}-2_train.csv')\n",
    "df_test = pd.read_csv(os.getcwd() + f'/data/sample-{sample_size}-2_test.csv')\n",
    "\n",
    "# Split dataset according to attack type and drop columns\n",
    "normal_df_train = df_train[df_train['label'] == 0].drop(columns=['attack_cat', 'label'])\n",
    "normal_df_test = df_test[df_test['label'] == 0].drop(columns=['attack_cat', 'label'])\n",
    "attack_df_train = df_train[df_train['label'] == 1].drop(columns=['attack_cat', 'label'])\n",
    "attack_df_test = df_test[df_test['label'] == 1].drop(columns=['attack_cat', 'label'])\n",
    "\n",
    "# Print dataset sizes in a table\n",
    "data = [\n",
    "    [\"Normal\", normal_df_train.shape[0] + normal_df_test.shape[0], normal_df_train.shape[0], normal_df_test.shape[0]],\n",
    "    [\"Attack\", attack_df_train.shape[0] + attack_df_test.shape[0], attack_df_train.shape[0], attack_df_test.shape[0]]\n",
    "]\n",
    "print(tabulate(data, headers=[\"Atack type\", \"Total\", \"Train\", \"Test\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Generate Feature Importance\n",
    "################################################################################\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "import time\n",
    "import numpy as np\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "dotenv.load_dotenv(os.getcwd() + '/../.env')\n",
    "\n",
    "template = \"\"\"\n",
    "You are provided with network data entries categorized as either normal or attack, along with their corresponding feature names.\n",
    "Carefully analyze the differences between normal and attack entries by comparing corresponding fields.\n",
    "Output top 5 important features that can be used to filter an entry as either normal or attack.\n",
    "Output only in the Python list structure.\n",
    "\n",
    "Feature Names:\n",
    "```{feature_names}```\n",
    "\n",
    "Normal Entries:\n",
    "```{normal_entries}```\n",
    "\n",
    "Attack Entries:\n",
    "```{attack_entries}```\n",
    "\n",
    "Example output:\n",
    "['feature1', 'feature2', 'feature3', 'feature4', 'feature5']\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"feature_names\", \"normal_entries\", \"attack_entries\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "model_name = \"gpt-4o\"\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.0)\n",
    "# model_name = \"gemini-1.5-pro\"\n",
    "chain = prompt | llm\n",
    "train_set_size = sample_size\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"unsw-nb15\",\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "\n",
    "normal_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'normal'})['embeddings']\n",
    "normal_mean_vector = np.mean(normal_vectors, axis=0).tolist()\n",
    "normal_documents = vector_store._collection.query(query_embeddings=[normal_mean_vector], n_results=10)['documents'][0]\n",
    "\n",
    "attack_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'attack'})['embeddings']\n",
    "attack_mean_vector = np.mean(attack_vectors, axis=0).tolist()\n",
    "attack_documents = vector_store._collection.query(query_embeddings=[attack_mean_vector], n_results=10)['documents'][0]\n",
    "\n",
    "completions = []\n",
    "for i in range(10):\n",
    "    completion = chain.invoke({\n",
    "        \"feature_names\": normal_df_train.columns.to_list(),\n",
    "        \"normal_entries\": \",\\n\".join([f\"{doc} --> normal\" for doc in normal_documents]),\n",
    "        \"attack_entries\": \",\\n\".join([f\"{doc} --> attack\" for doc in attack_documents])\n",
    "        })\n",
    "    completions.append(completion.content)\n",
    "    print(completion.content)\n",
    "    time.sleep(10)\n",
    "\n",
    "with open(f\"results/feature-importance-{sample_size}-llm-{model_name}.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\".join(completions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S4025371\\OneDrive - RMIT University\\Repositories\\iot-llm\\.conda\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"proto\": \"if proto == 'udp' then attack else normal\",\n",
      "  \"state\": \"if state == 'INT' then attack else normal\",\n",
      "  \"dpkts\": \"if dpkts == 0 then attack else normal\",\n",
      "  \"dbytes\": \"if dbytes == 0 then attack else normal\",\n",
      "  \"rate\": \"if rate > 100000 then attack else normal\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Generate Rules\n",
    "################################################################################\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "dotenv.load_dotenv(os.getcwd() + '/../.env')\n",
    "\n",
    "template = \"\"\"\n",
    "You are provided with network data entries categorized as either normal or attack, along with their corresponding feature names.\n",
    "Carefully analyze the differences between normal and attack entries by comparing corresponding fields.\n",
    "Generate 5 simple and deterministic rules for top 5 important features to filter an entry as either normal or attack. \n",
    "Output only in the JSON format with the structure: \n",
    "{{'feature1': 'rule', 'feature2': 'rule', 'feature3': 'rule', 'feature4': 'rule', 'feature5': 'rule'}}.\n",
    "\n",
    "Feature Names:\n",
    "```{feature_names}```\n",
    "\n",
    "Normal Entries:\n",
    "```{normal_entries}```\n",
    "\n",
    "Attack Entries:\n",
    "```{attack_entries}```\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"feature_names\", \"normal_entries\", \"attack_entries\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "model_name = \"gpt-4o\"\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.0)\n",
    "# model_name = \"gemini-1.5-pro\"\n",
    "# llm = ChatAnthropic(model='claude-3-opus-20240229')\n",
    "# model_name = \"claude-3-opus-20240229\"\n",
    "chain = prompt | llm\n",
    "train_set_size = sample_size\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"unsw-nb15\",\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "\n",
    "normal_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'normal'})['embeddings']\n",
    "normal_mean_vector = np.mean(normal_vectors, axis=0).tolist()\n",
    "normal_documents = vector_store._collection.query(query_embeddings=[normal_mean_vector], n_results=10)['documents']\n",
    "\n",
    "attack_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'attack'})['embeddings']\n",
    "attack_mean_vector = np.mean(attack_vectors, axis=0).tolist()\n",
    "attack_documents = vector_store._collection.query(query_embeddings=[attack_mean_vector], n_results=10)['documents']\n",
    "\n",
    "completion = chain.invoke({\n",
    "    \"feature_names\": normal_df_train.columns.to_list(),\n",
    "    \"normal_entries\": \",\\n\".join([f\"{doc} --> normal\" for doc in normal_documents]),\n",
    "    \"attack_entries\": \",\\n\".join([f\"{doc} --> attack\" for doc in attack_documents])\n",
    "    })\n",
    "\n",
    "print(completion.content)\n",
    "\n",
    "with open(f\"results/generated-rules-{sample_size}-llm-{model_name}.txt\", \"a\") as f:\n",
    "    f.write(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting normal entries...: 100%|███████████████████████████| 1000/1000 [00:00<00:00, 1951.35it/s]\n",
      "Predicting attack entries...: 100%|███████████████████████████| 1000/1000 [00:00<00:00, 2273.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack       1.00      0.96      0.98      1000\n",
      "      normal       0.96      1.00      0.98      1000\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.98      0.98      0.98      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "[[ 963   37]\n",
      " [   0 1000]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Evaluate generated rule\n",
    "################################################################################\n",
    "\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "datasets = {\"normal\": normal_df_test, \"attack\": attack_df_test}\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for attack_type, dataset in datasets.items():\n",
    "    test_set_size = dataset.shape[0]\n",
    "    predicted_attack_types = []\n",
    "    for i in tqdm(range(test_set_size), ncols=100, desc=f\"Predicting {attack_type} entries...\"):\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['proto'] == \"udp\" else \"normal\")\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['state'] == \"INT\" else \"normal\")\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['dpkts'] == 0 else \"normal\")\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['dbytes'] == 0 else \"normal\")\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['rate'] > 100000 else \"normal\")\n",
    "        y_true.append(attack_type)\n",
    "        y_pred.append(mode(predicted_attack_types))\n",
    "\n",
    "c_report = classification_report(y_true, y_pred)\n",
    "c_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "with open(f\"results/result-llm-{sample_size}-2.txt\", \"w\") as f:\n",
    "    f.write(f\"Classication Report\\n{c_report}\\n\\nConfusion Matrix\\n{c_matrix}\")\n",
    "\n",
    "print(c_report)\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/home/s4025371/anaconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='To separate attack and normal network data entries, we can look for distinguishing patterns or characteristics in the provided data. Here are some key observations that can help in differentiating between attack and normal entries:\\n\\n1. **Packet Counts (`spkts` and `dpkts`)**:\\n   - Attack entries tend to have a lower number of destination packets (`dpkts`). For example, `dpkts` values for attack entries are often 6 or 8, whereas normal entries have values like 8, 10, or 18.\\n\\n2. **Byte Counts (`sbytes` and `dbytes`)**:\\n   - Attack entries generally have lower destination byte counts (`dbytes`). For instance, attack entries have `dbytes` values like 268 and 1032, while normal entries have higher values like 1120, 1330, and 10168.\\n\\n3. **Load (`sload` and `dload`)**:\\n   - Attack entries show significantly lower destination load (`dload`). For example, attack entries have `dload` values like 5092.992676 and 30557.85742, whereas normal entries have higher values like 17406.63281, 14472.77734, and 76229.71094.\\n\\n4. **Inter-packet Arrival Time (`sinpkt` and `dinpkt`)**:\\n   - Attack entries often have lower inter-packet arrival times (`sinpkt` and `dinpkt`). For instance, attack entries have `sinpkt` values like 26.267111 and 36.386556, while normal entries have higher values like 50.044778, 73.517333, and 77.504925.\\n\\n5. **Jitter (`sjit` and `djit`)**:\\n   - Attack entries tend to have lower jitter values (`sjit` and `djit`). For example, attack entries have `sjit` values like 1405.680404 and 1815.063658, whereas normal entries have higher values like 2552.511185, 4564.721941, and 8766.759237.\\n\\n6. **TCP Round Trip Time (`tcprtt`)**:\\n   - Attack entries often have lower TCP round trip times (`tcprtt`). For instance, attack entries have `tcprtt` values like 0.058905 and 0.080215, while normal entries have higher values like 0.15083, 0.109361, and 0.00066.\\n\\n7. **Mean Packet Size (`smean` and `dmean`)**:\\n   - Attack entries generally have lower mean packet sizes (`dmean`). For example, attack entries have `dmean` values like 45 and 129, whereas normal entries have higher values like 140, 133, and 565.\\n\\n8. **Connection Depth (`trans_depth`)**:\\n   - Attack entries often have a connection depth (`trans_depth`) of 1, while normal entries can have higher values like 1 or 0.\\n\\n9. **Response Body Length (`response_body_len`)**:\\n   - Attack entries typically have a response body length (`response_body_len`) of 0, while normal entries can have higher values like 109, 158, 220, and 3924.\\n\\n10. **Service Count (`ct_srv_src`)**:\\n    - Attack entries often have a service count (`ct_srv_src`) of 2, while normal entries can have higher values like 2, 7, and 6.\\n\\n11. **State Count (`ct_state_ttl`)**:\\n    - Attack entries often have a state count (`ct_state_ttl`) of 1, while normal entries can have higher values like 1, 2, and 3.\\n\\n12. **Destination Service Count (`ct_srv_dst`)**:\\n    - Attack entries often have a destination service count (`ct_srv_dst`) of 1, while normal entries can have higher values like 1, 2, and 3.\\n\\nBy focusing on these key features, one can develop a simple rule-based approach or use machine learning techniques to classify network data entries as either attack or normal.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 865, 'prompt_tokens': 2012, 'total_tokens': 2877}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5', 'finish_reason': 'stop', 'logprobs': None} id='run-f74f8029-a8fc-4893-a084-597d7fe4264f-0' usage_metadata={'input_tokens': 2012, 'output_tokens': 865, 'total_tokens': 2877}\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Get a Summary\n",
    "################################################################################\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "dotenv.load_dotenv(os.getcwd() + '/../.env')\n",
    "\n",
    "template = \"\"\"\n",
    "Given normal and attack network data entries, output human understandable small summary on \n",
    "how attack and normal entries can be simply separated.\n",
    "\n",
    "Feature Names:\n",
    "```{feature_names}```\n",
    "\n",
    "Normal Entries:\n",
    "```{normal_entries}```\n",
    "\n",
    "Attack Entries:\n",
    "```{attack_entries}```\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"feature_names\", \"normal_entries\", \"attack_entries\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")\n",
    "chain = prompt | llm\n",
    "train_set_size = sample_size\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"unsw-nb15\",\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 5, \"fetch_k\": 5})\n",
    "normal_documents = retriever.invoke(str(normal_df_test.iloc[0].to_list()), filter={\"source\": \"unsw-nb15\", \"label\": \"normal\"})\n",
    "attack_documents = retriever.invoke(str(attack_df_test.iloc[0].to_list()), filter={\"source\": \"unsw-nb15\", \"label\": \"attack\"})\n",
    "completion = chain.invoke({\n",
    "    \"feature_names\": normal_df_train.columns.to_list(),\n",
    "    \"normal_entries\": \",\\n\".join([f\"{doc.page_content} --> {doc.metadata['label']}\" for doc in normal_documents]),\n",
    "    \"attack_entries\": \",\\n\".join([f\"{doc.page_content} --> {doc.metadata['label']}\" for doc in attack_documents])\n",
    "    })\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens: 2780\n"
     ]
    }
   ],
   "source": [
    "# print(completion.text)\n",
    "import tiktoken     # https://github.com/openai/tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "num_tokens = len(encoding.encode(str(completion.text)))\n",
    "print(\"Num tokens:\", num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# \n",
    "################################################################################\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "template = \"\"\"\n",
    "Your task is to identify whether the query is attack or normal. Then \n",
    "generate a policy to filter the given query based on the values. \n",
    "You will be given feature names of the entries and similar entries along \n",
    "with the input query to make a decision.\n",
    "\n",
    "Feature Names:\n",
    "```{feature_names}```\n",
    "\n",
    "Similar Entries:\n",
    "```{similar_entries}```\n",
    "\n",
    "Input Query: \n",
    "```{query}```\n",
    "\n",
    "Policy:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"feature_names\", \"similar_entries\", \"query\"])\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")\n",
    "chain = prompt | llm\n",
    "train_set_size = sample_size\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"cic-iot\",\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 5, \"fetch_k\": 5})\n",
    "query_document = str(normal_df_test.iloc[5].to_list())\n",
    "similar_documents = retriever.invoke(query_document, filter={\"source\": \"cic-iot\"})\n",
    "chain.invoke({\n",
    "    \"feature_names\": normal_df_train.columns.to_list(),\n",
    "    \"similar_entries\": \",\\n\".join([f\"{doc.page_content} --> {doc.metadata['label']}\" for doc in similar_documents]),\n",
    "    \"query\": query_document\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('llm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae27029e1f82e56f496a30980cc01ee9e9874fa5eb01d56792517e894009f269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
