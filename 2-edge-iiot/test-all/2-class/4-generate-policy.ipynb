{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Training set size:  (106799, 61)\n",
      "Attack Test set size:  (26700, 61)\n",
      "Normal Training set size:  (19441, 61)\n",
      "Normal Test set size:  (4860, 61)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load dateset\n",
    "df = pd.read_csv(os.getcwd() + '/../../data/edge-iiot/Edge-IIoTset dataset/Selected dataset for ML and DL/ML-EdgeIIoT-dataset.csv', low_memory=False)\n",
    "attack_df = df[df['Attack_label'] == 1]\n",
    "attack_df = attack_df.drop(columns=['Attack_label', 'Attack_type'])\n",
    "attack_df_train = attack_df.sample(frac=0.8, random_state=42)\n",
    "attack_df_test = attack_df.drop(attack_df_train.index)\n",
    "\n",
    "normal_df = df[df['Attack_label'] == 0]\n",
    "normal_df = normal_df.drop(columns=['Attack_label', 'Attack_type'])\n",
    "normal_df_train = normal_df.sample(frac=0.8, random_state=42)\n",
    "normal_df_test = normal_df.drop(normal_df_train.index)\n",
    "\n",
    "print(\"Attack Training set size: \", attack_df_train.shape)\n",
    "print(\"Attack Test set size: \", attack_df_test.shape)\n",
    "\n",
    "print(\"Normal Training set size: \", normal_df_train.shape)\n",
    "print(\"Normal Test set size: \", normal_df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/home/s4025371/anaconda3/envs/llm/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/opt/home/s4025371/anaconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"edge-iiotset\",\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=\"./chroma_db_binary\")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 5, \"fetch_k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarities between the INPUT packet and the SIMILAR packets are as follows:\n",
      "\n",
      "1. 'ip.src_host', 'ip.dst_host': Both the INPUT and SIMILAR packets have the same source and destination IP addresses.\n",
      "2. 'tcp.dstport': The TCP destination port is the same in both the INPUT and SIMILAR packets.\n",
      "3. 'mqtt.msg': The MQTT message field is the same in both the INPUT and SIMILAR packets.\n",
      "4. 'tcp.flags': The TCP flags field is the same in both the INPUT and SIMILAR packets.\n",
      "5. 'tcp.seq': The TCP sequence number field is the same in both the INPUT and SIMILAR packets.\n",
      "\n",
      "These similarities indicate that the packets have similar network characteristics related to IP addresses, ports, protocol messages, and TCP flags and sequence numbers.\n",
      "The similarities between the INPUT packet and the SIMILAR packets are as follows:\n",
      "\n",
      "1. Both the INPUT and SIMILAR packets have the same source and destination IP addresses: '192.168.0.101' and '192.168.0.128' respectively.\n",
      "2. The protocol being used in both packets is '0'.\n",
      "3. The 'arp.src.proto_ipv4' is '0' in both packets.\n",
      "4. The 'icmp.checksum' is '0.0' in both packets.\n",
      "5. The 'icmp.seq_le' is '0.0' in both packets.\n",
      "6. The 'icmp.transmit_timestamp' is '0.0' in both packets.\n",
      "7. The 'icmp.unused' is '0.0' in both packets.\n",
      "8. The 'tcp.connection.syn' is '0.0' in both packets.\n",
      "9. The 'tcp.dstport' is '1883.0' in both packets.\n",
      "10. The 'tcp.flags' is '16.0' in both packets.\n",
      "11. The 'tcp.flags.ack' is '1.0' in both packets.\n",
      "12. The 'tcp.len' is '0.0' in both packets.\n",
      "13. The 'tcp.srcport' is '0' in both packets.\n",
      "14. The 'mqtt.len' is '0.0' in both packets.\n",
      "15. The 'mqtt.ver' is '0.0' in both packets.\n",
      "16. The 'mbtcp.len' is '0.0' in both packets.\n",
      "17. The 'mbtcp.trans_id' is '0.0' in both packets.\n",
      "The similarities between the INPUT and SIMILAR packet data can be identified by comparing the values in each field. Here are some similarities based on the provided data:\n",
      "\n",
      "1. `ip.src_host`: Both INPUT and SIMILAR packets have the same source IP address '192.168.0.128'.\n",
      "2. `ip.dst_host`: Both INPUT and SIMILAR packets have the same destination IP address '192.168.0.101'.\n",
      "3. `tcp.flags`: The TCP flags in both INPUT and SIMILAR packets are '0'.\n",
      "4. `tcp.dstport`: The TCP destination port in both INPUT and SIMILAR packets is '1883.0'.\n",
      "5. `tcp.seq`: The TCP sequence number in both INPUT and SIMILAR packets is '0'.\n",
      "\n",
      "These are some of the similarities between the two sets of network packet data based on the provided information.\n"
     ]
    }
   ],
   "source": [
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "llm = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Given a network packet data in `INPUT` and similar network packet data in `SIMILAR`. Output the similarities between the INPUT and SIMILAR.\"),\n",
    "    (\"user\", \"HEADERS:\\n{headers}\\n\\nINPUT:\\n{input}\\n\\nSIMILAR:\\n{similar}\")\n",
    "])\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "sample_size = 3 # attack_df_test.shape[0]\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "headers = \"'frame.time', 'ip.src_host', 'ip.dst_host', 'arp.dst.proto_ipv4', 'arp.opcode', 'arp.hw.size', 'arp.src.proto_ipv4', 'icmp.checksum', 'icmp.seq_le', 'icmp.transmit_timestamp', 'icmp.unused', 'http.file_data', 'http.content_length', 'http.request.uri.query', 'http.request.method', 'http.referer', 'http.request.full_uri', 'http.request.version', 'http.response', 'http.tls_port', 'tcp.ack', 'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin', 'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack', 'tcp.dstport', 'tcp.flags', 'tcp.flags.ack', 'tcp.len', 'tcp.options', 'tcp.payload', 'tcp.seq', 'tcp.srcport', 'udp.port', 'udp.stream', 'udp.time_delta', 'dns.qry.name', 'dns.qry.name.len', 'dns.qry.qu', 'dns.qry.type', 'dns.retransmission', 'dns.retransmit_request', 'dns.retransmit_request_in', 'mqtt.conack.flags', 'mqtt.conflag.cleansess', 'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg_decoded_as', 'mqtt.msg', 'mqtt.msgtype', 'mqtt.proto_len', 'mqtt.protoname', 'mqtt.topic', 'mqtt.topic_len', 'mqtt.ver', 'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id']\"\n",
    "\n",
    "for i in range(sample_size):\n",
    "    query_document = str(normal_df_test.iloc[i].to_list())\n",
    "    similar_documents = retriever.invoke(query_document, filter={\"source\": \"edge-iiotset\"})\n",
    "    response = chain.invoke({\n",
    "        \"headers\": headers, \n",
    "        \"input\": str(query_document), \n",
    "        \"similar\": \"\\n\".join([similar_document.page_content for similar_document in similar_documents])\n",
    "    })\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
