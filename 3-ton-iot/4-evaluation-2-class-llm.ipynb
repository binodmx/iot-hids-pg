{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+---------+--------+\n",
      "| Atack type   |   Total |   Train |   Test |\n",
      "+==============+=========+=========+========+\n",
      "| Normal       |   42040 |   33632 |   8408 |\n",
      "+--------------+---------+---------+--------+\n",
      "| Attack       |   57960 |   46368 |  11592 |\n",
      "+--------------+---------+---------+--------+\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Load dataset and split it into training and test set\n",
    "################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "dataset_name = \"ton-iot\"\n",
    "sample_size = 100000\n",
    "\n",
    "# Load dateset\n",
    "df = pd.read_csv(os.getcwd() + f'/data/sample-{sample_size}-2.csv')\n",
    "\n",
    "# Split dataset according to attack type\n",
    "normal_df = df[df['label'] == 0]\n",
    "attack_df = df[df['label'] == 1]\n",
    "\n",
    "# Drop columns\n",
    "normal_df = normal_df.drop(columns=['label', 'type'])\n",
    "attack_df = attack_df.drop(columns=['label', 'type'])\n",
    "\n",
    "# Split dataset into training and test set\n",
    "normal_df_train = normal_df.sample(frac=0.8, random_state=42)\n",
    "normal_df_test = normal_df.drop(normal_df_train.index)\n",
    "attack_df_train = attack_df.sample(frac=0.8, random_state=42)\n",
    "attack_df_test = attack_df.drop(attack_df_train.index)\n",
    "\n",
    "# Print dataset sizes in a table\n",
    "data = [\n",
    "    [\"Normal\", normal_df.shape[0], normal_df_train.shape[0], normal_df_test.shape[0]],\n",
    "    [\"Attack\", attack_df.shape[0], attack_df_train.shape[0], attack_df_test.shape[0]]\n",
    "]\n",
    "print(tabulate(data, headers=[\"Atack type\", \"Total\", \"Train\", \"Test\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Generate Feature Importance\n",
    "################################################################################\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "dotenv.load_dotenv(os.getcwd() + '/../.env')\n",
    "\n",
    "template = \"\"\"\n",
    "You are provided with network data entries categorized as either normal or attack, along with their corresponding feature names.\n",
    "Carefully analyze the differences between normal and attack entries by comparing corresponding fields.\n",
    "Output top 10 important features that can be used to filter an entry as either normal or attack.\n",
    "Output only in the Python list structure.\n",
    "\n",
    "Normal Entries:\n",
    "```{normal_entries}```\n",
    "\n",
    "Attack Entries:\n",
    "```{attack_entries}```\n",
    "\n",
    "Example output:\n",
    "['feature1', 'feature2', 'feature3', ..., 'feature10']\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"normal_entries\", \"attack_entries\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "model_name = \"gpt-4o\"\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.0)\n",
    "# model_name = \"gemini-1.5-pro\"\n",
    "# llm = ChatAnthropic(model='claude-3-opus-20240229')\n",
    "# model_name = \"claude-3-opus-20240229\"\n",
    "chain = prompt | llm\n",
    "train_set_size = sample_size\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=dataset_name,\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "\n",
    "normal_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'normal'})['embeddings']\n",
    "normal_mean_vector = np.mean(normal_vectors, axis=0).tolist()\n",
    "normal_documents = vector_store._collection.query(query_embeddings=[normal_mean_vector], n_results=10)['documents'][0]\n",
    "\n",
    "attack_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'attack'})['embeddings']\n",
    "attack_mean_vector = np.mean(attack_vectors, axis=0).tolist()\n",
    "attack_documents = vector_store._collection.query(query_embeddings=[attack_mean_vector], n_results=10)['documents'][0]\n",
    "\n",
    "normal_entries = {}\n",
    "for i, feature_name in enumerate(normal_df_train.columns.to_list()):\n",
    "    normal_entries[feature_name] = [json.loads(doc)[i] for doc in normal_documents]\n",
    "\n",
    "attack_entries = {}\n",
    "for i, feature_name in enumerate(attack_df_train.columns.to_list()):\n",
    "    attack_entries[feature_name] = [json.loads(doc)[i] for doc in attack_documents]\n",
    "\n",
    "completions = []\n",
    "for i in range(10):\n",
    "    completion = chain.invoke({\n",
    "        \"normal_entries\": json.dumps(normal_entries),\n",
    "        \"attack_entries\": json.dumps(attack_entries)\n",
    "    })\n",
    "    completions.append(completion.content)\n",
    "    print(completion.content)\n",
    "    time.sleep(10)\n",
    "\n",
    "with open(f\"results/feature-importance-{sample_size}-llm-{model_name}.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\".join(completions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S4025371\\OneDrive - RMIT University\\Repositories\\iot-llm\\.conda\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"proto\": \"If proto is 'udp', then entry is normal; if proto is 'tcp', then entry is attack.\",\n",
      "    \"service\": \"If service is 'dns', then entry is normal; if service is '-', then entry is attack.\",\n",
      "    \"conn_state\": \"If conn_state is 'S0', then entry is normal; if conn_state is 'SF' or 'REJ', then entry is attack.\",\n",
      "    \"dns_query\": \"If dns_query is 'desktop-7q9apbo', then entry is normal; if dns_query is '-', then entry is attack.\",\n",
      "    \"dst_port\": \"If dst_port is 5355, then entry is normal; if dst_port is 80, then entry is attack.\"\n",
      "}\n",
      "```\n",
      "Prompt tokens: 2761\n",
      "Completion tokens: 159\n",
      "Total tokens: 2920\n",
      "Percentage of tokens used: 0.0228125\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Generate Rules with transposed data\n",
    "################################################################################\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "import uuid\n",
    "import tiktoken     # https://github.com/openai/tiktoken\n",
    "\n",
    "dotenv.load_dotenv(os.getcwd() + '/../.env')\n",
    "\n",
    "template = \"\"\"\n",
    "You are provided with network data entries categorized as either normal or attack, along with their corresponding feature names.\n",
    "Carefully analyze the differences between normal and attack entries by comparing corresponding fields.\n",
    "Generate 5 simple and deterministic rules for top 5 important features to filter an entry as either normal or attack. \n",
    "Output only in the JSON format with the structure: \n",
    "{{'feature1': 'rule', 'feature2': 'rule', ..., 'feature5': 'rule'}}.\n",
    "\n",
    "Normal Entries:\n",
    "```{normal_entries}```\n",
    "\n",
    "Attack Entries:\n",
    "```{attack_entries}```\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"normal_entries\", \"attack_entries\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "model_name = \"gpt-4o\"\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.0)\n",
    "# model_name = \"gemini-1.5-pro\"\n",
    "# llm = ChatAnthropic(model='claude-3-opus-20240229')\n",
    "# model_name = \"claude-3-opus-20240229\"\n",
    "chain = prompt | llm\n",
    "train_set_size = sample_size\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=dataset_name,\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "\n",
    "normal_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'normal'})['embeddings']\n",
    "normal_mean_vector = np.mean(normal_vectors, axis=0).tolist()\n",
    "normal_documents = vector_store._collection.query(query_embeddings=[normal_mean_vector], n_results=10)['documents'][0]\n",
    "\n",
    "attack_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'attack'})['embeddings']\n",
    "attack_mean_vector = np.mean(attack_vectors, axis=0).tolist()\n",
    "attack_documents = vector_store._collection.query(query_embeddings=[attack_mean_vector], n_results=10)['documents'][0]\n",
    "\n",
    "normal_entries = {}\n",
    "for i, feature_name in enumerate(normal_df_train.columns.to_list()):\n",
    "    normal_entries[feature_name] = [json.loads(doc.replace(\"'\", \"\\\"\"))[i] for doc in normal_documents]\n",
    "\n",
    "attack_entries = {}\n",
    "for i, feature_name in enumerate(attack_df_train.columns.to_list()):\n",
    "    attack_entries[feature_name] = [json.loads(doc.replace(\"'\", \"\\\"\"))[i] for doc in attack_documents]\n",
    "\n",
    "# prompt_text = prompt.invoke({\n",
    "#     \"normal_entries\": json.dumps(normal_entries),\n",
    "#     \"attack_entries\": json.dumps(attack_entries)\n",
    "# }).text\n",
    "\n",
    "# print(prompt_text)\n",
    "\n",
    "completion = chain.invoke({\n",
    "    \"normal_entries\": json.dumps(normal_entries),\n",
    "    \"attack_entries\": json.dumps(attack_entries)\n",
    "})\n",
    "\n",
    "print(completion.content)\n",
    "\n",
    "id = str(uuid.uuid4())\n",
    "with open(f\"results/llm/generated-rules-{sample_size}-llm-{model_name}.txt\", \"a\") as f:\n",
    "    f.write(f\"{id}\\n\")\n",
    "    f.write(f\"{completion.content}\\n\")\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "num_tokens_prompt = len(encoding.encode(prompt.invoke({\"normal_entries\": json.dumps(normal_entries),\"attack_entries\": json.dumps(attack_entries)}).text))\n",
    "num_tokens_completion = len(encoding.encode(str(completion.content)))\n",
    "\n",
    "print(f\"Prompt tokens: {num_tokens_prompt}\")\n",
    "print(f\"Completion tokens: {num_tokens_completion}\")\n",
    "print(f\"Total tokens: {num_tokens_prompt + num_tokens_completion}\")\n",
    "print(f\"Percentage of tokens used: {(num_tokens_prompt + num_tokens_completion) / 128000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting normal entries...: 100%|███████████████████████████| 1000/1000 [00:00<00:00, 1377.62it/s]\n",
      "Predicting attack entries...: 100%|███████████████████████████| 1000/1000 [00:00<00:00, 1556.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack     0.7530    0.9300    0.8322      1000\n",
      "      normal     0.9085    0.6950    0.7875      1000\n",
      "\n",
      "    accuracy                         0.8125      2000\n",
      "   macro avg     0.8308    0.8125    0.8099      2000\n",
      "weighted avg     0.8308    0.8125    0.8099      2000\n",
      "\n",
      "[[930  70]\n",
      " [305 695]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Evaluate generated rules\n",
    "################################################################################\n",
    "\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "datasets = {\"normal\": normal_df_test, \"attack\": attack_df_test}\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for attack_type, dataset in datasets.items():\n",
    "    test_set_size = dataset.shape[0]\n",
    "    for i in tqdm(range(test_set_size), ncols=100, desc=f\"Predicting {attack_type} entries...\"):\n",
    "        predicted_attack_types = []\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['proto'] == \"udp\" else \"attack\")\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['service'] == \"dns\" else \"attack\")\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['conn_state'] == \"S0\" else \"attack\")\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['dns_query'] == 'desktop-7q9apbo' else \"attack\")\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['dst_port'] == 5355 else \"attack\")\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['proto'] == \"tcp\" else \"normal\")\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['service'] == \"-\" else \"normal\")\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['conn_state'] in [\"SF\", \"REJ\"] else \"normal\")\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['dns_query'] == '-' else \"normal\")\n",
    "        predicted_attack_types.append(\"attack\" if dataset.iloc[i]['dst_port'] == 80 else \"normal\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['duration'] < 0.001 else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['src_bytes'] == 66 else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['dst_bytes'] == 0 else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['missed_bytes'] == 0 else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['src_pkts'] == 2 else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['src_ip'] == \"192.168.1.195\" else \"attack\")\n",
    "        y_true.append(attack_type)\n",
    "        y_pred.append(mode(predicted_attack_types))\n",
    "\n",
    "c_report = classification_report(y_true, y_pred, digits=4)\n",
    "c_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "with open(f\"results/llm/result-llm-{sample_size}-2.txt\", \"a\") as f:\n",
    "    f.write(f\"{id}\\n\")\n",
    "    f.write(f\"Classication Report\\n{c_report}\\n\\nConfusion Matrix\\n{c_matrix}\\n\")\n",
    "\n",
    "print(c_report)\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Prompt Template\n",
    "################################################################################\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "system_message = (\"system\",\n",
    "\"\"\"\n",
    "You are a good data analyst.\n",
    "You are provided with network data entries categorized as either normal or attack, along with their corresponding feature names.\n",
    "Carefully analyze the differences between normal and attack entries by comparing corresponding fields.\n",
    "Your task is to generate {k} simple and deterministic rules for top {k} important features to filter attack entries.\n",
    "Supported operators are '==', '!=', '>', '<', '>=', '<='.\n",
    "Generate exactly {k} rules to filter attack entries and make a tool call for each rule.\n",
    "\"\"\"\n",
    ")\n",
    "human_message = (\"user\",\n",
    "\"\"\"\n",
    "Analyze the following network data and generate rules for the top 5 important features to filter attack entries.\n",
    "\n",
    "Normal Entries:\n",
    "```{normal_entries}```\n",
    "\n",
    "Attack Entries:\n",
    "```{attack_entries}```\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    human_message,\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "# Invoke prompt\n",
    "# prompt.invoke({\"k\": 5, \"normal_entries\": normal_entries, \"attack_entries\": attack_entries, \"msgs\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Tool\n",
    "################################################################################\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "show_progress = True\n",
    "operations = {'<': operator.lt, '>': operator.gt, '==': operator.eq, '<=': operator.le, '>=': operator.ge, '!=': operator.ne}\n",
    "\n",
    "@tool\n",
    "def evaluate_rule(\n",
    "    feature_name: Annotated[str, \"Feature name\"],\n",
    "    value: Annotated[str, \"Value\"], \n",
    "    op: Annotated[str, \"Operator\"]\n",
    ") -> bool:\n",
    "    \"\"\"Evaluate the rule and return the macro f1-score.\"\"\"\n",
    "    try:\n",
    "        value = float(value)\n",
    "    except ValueError:\n",
    "        value\n",
    "    datasets = {\"normal\": normal_df_train, \"attack\": attack_df_train}\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    if op in operations:\n",
    "        for attack_type, dataset in datasets.items():\n",
    "            test_set_size = dataset.shape[0]\n",
    "            for i in tqdm(range(test_set_size), ncols=100, desc=f\"Predicting {attack_type} entries...\", disable=not show_progress):\n",
    "                y_true.append(attack_type)\n",
    "                y_pred.append(\"attack\" if operations[op](dataset.iloc[i][feature_name], value) else \"normal\")\n",
    "        c_report = classification_report(y_true, y_pred, digits=4, output_dict=True)\n",
    "        return c_report['macro avg']['f1-score']\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported operator: {op}\")\n",
    "\n",
    "# Invoke tool\n",
    "# print(evaluate_rule.invoke({\"feature_name\": \"flow_duration\", \"value\": \"1\", \"op\": \"<\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# LLM\n",
    "################################################################################\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "dotenv.load_dotenv(os.getcwd() + '/../.env')\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "llm = ChatOpenAI(model=model_name, temperature=0.1)\n",
    "# model_name = \"gemini-1.5-pro\"\n",
    "# llm = ChatGoogleGenerativeAI(model=model_name, temperature=0.0)\n",
    "# model_name = \"claude-3-opus-20240229\"\n",
    "# llm = ChatAnthropic(model=model_name, temperature=0.0)\n",
    "\n",
    "llm_with_tool = llm.bind_tools([evaluate_rule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Vector Store\n",
    "################################################################################\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "train_set_size = sample_size\n",
    "n_results = 10\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=dataset_name,\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "\n",
    "normal_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'normal'})['embeddings']\n",
    "normal_mean_vector = np.mean(normal_vectors, axis=0).tolist()\n",
    "normal_documents = vector_store._collection.query(query_embeddings=[normal_mean_vector], n_results=n_results)['documents'][0]\n",
    "\n",
    "attack_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'attack'})['embeddings']\n",
    "attack_mean_vector = np.mean(attack_vectors, axis=0).tolist()\n",
    "attack_documents = vector_store._collection.query(query_embeddings=[attack_mean_vector], n_results=n_results)['documents'][0]\n",
    "\n",
    "normal_entries_dict = {}\n",
    "for i, feature_name in enumerate(normal_df_train.columns.to_list()):\n",
    "    normal_entries_dict[feature_name] = [json.loads(doc.replace(\"'\", \"\\\"\"))[i] for doc in normal_documents]\n",
    "\n",
    "attack_entries_dict = {}\n",
    "for i, feature_name in enumerate(attack_df_train.columns.to_list()):\n",
    "    attack_entries_dict[feature_name] = [json.loads(doc.replace(\"'\", \"\\\"\"))[i] for doc in attack_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1 Current mean f1-score: 0.630859345128614 Token usage: {'completion_tokens': 355, 'prompt_tokens': 2814, 'total_tokens': 3169}\n",
      "Round: 2 Current mean f1-score: 0.6839445189143156 Token usage: {'completion_tokens': 405, 'prompt_tokens': 3343, 'total_tokens': 3748}\n",
      "Round: 3 Current mean f1-score: 0.5795140335456447 Token usage: {'completion_tokens': 445, 'prompt_tokens': 3923, 'total_tokens': 4368}\n",
      "Round: 4 Current mean f1-score: 0.631331024544524 Token usage: {'completion_tokens': 438, 'prompt_tokens': 4543, 'total_tokens': 4981}\n",
      "Round: 5 Current mean f1-score: 0.6425807218772863 Token usage: {'completion_tokens': 396, 'prompt_tokens': 5155, 'total_tokens': 5551}\n",
      "[0.630859345128614, 0.6839445189143156, 0.5795140335456447, 0.631331024544524, 0.6425807218772863]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Chain\n",
    "################################################################################\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chain = prompt | llm_with_tool\n",
    "\n",
    "n_repetitions = 5\n",
    "context_window = 128000\n",
    "show_progress = False\n",
    "\n",
    "def get_initial_state():\n",
    "  n = 0\n",
    "  k = 5\n",
    "  mean_f1s = 0\n",
    "  max_f1s = 0\n",
    "  n_max = 0\n",
    "  token_usage = {}\n",
    "  normal_entries = json.dumps(normal_entries_dict)\n",
    "  attack_entries = json.dumps(attack_entries_dict)\n",
    "  msgs = []\n",
    "  return locals()\n",
    "\n",
    "state = get_initial_state()\n",
    "train_f1_scores = []\n",
    "while state[\"n\"] < n_repetitions:\n",
    "    ai_msg = chain.invoke(state)\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        tool_msg = evaluate_rule.invoke(tool_call)\n",
    "        tool_msgs.append(tool_msg)\n",
    "    state[\"mean_f1s\"] = sum(float(msg.content) for msg in tool_msgs) / len(tool_msgs)\n",
    "    human_msg = HumanMessage(f\"The current mean f1-score for the generated rules is {state['mean_f1s']}. \"\n",
    "                             \"If this mean f1-score is greater than the previous rounds, keep the better performing \"\n",
    "                             \"rules and revise or replace only the underperforming ones (those with a score less than mean). \"\n",
    "                             \"Otherwise, revise or replace any rules that have a score less than mean. \"\n",
    "                             f\"Based on the feedback, generate exactly {state['k']} rules to filter attack entries and \"\n",
    "                             \"make a tool call for each rule, ensuring that a tool call is made for every entry every time.\")\n",
    "    state[\"n\"] += 1\n",
    "    state[\"msgs\"].extend([ai_msg, *tool_msgs, human_msg])\n",
    "    train_f1_scores.append(state[\"mean_f1s\"])\n",
    "    state[\"max_f1s\"] = state[\"mean_f1s\"] if state[\"mean_f1s\"] > state[\"max_f1s\"] else state[\"max_f1s\"]\n",
    "    state[\"n_max\"] = state[\"n\"] if state[\"mean_f1s\"] > state[\"max_f1s\"] else state[\"n_max\"]\n",
    "    state[\"token_usage\"] = {key: ai_msg.response_metadata[\"token_usage\"][key] for key in [\"completion_tokens\", \"prompt_tokens\", \"total_tokens\"]} \n",
    "    print(\"Round:\", state[\"n\"], \"Current mean f1-score:\", state[\"mean_f1s\"], \"Token usage:\", state[\"token_usage\"])\n",
    "\n",
    "print(train_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack if src_ip != 192.168.1.17 else normal\n",
      "attack if proto == tcp else normal\n",
      "attack if service == - else normal\n",
      "attack if conn_state == SF else normal\n",
      "attack if dns_query == - else normal\n",
      "0.8076550589224163\n",
      "0.7954343971631206\n",
      "attack if src_ip == 192.168.1.31 else normal\n",
      "attack if proto == tcp else normal\n",
      "attack if service == - else normal\n",
      "attack if dst_port == 80 else normal\n",
      "attack if dns_query == - else normal\n",
      "0.8388243850646617\n",
      "0.8342749529190208\n",
      "attack if src_bytes == 0 else normal\n",
      "attack if proto == tcp else normal\n",
      "attack if duration > 0 else normal\n",
      "attack if missed_bytes > 0 else normal\n",
      "attack if dns_query == - else normal\n",
      "0.7833477985868386\n",
      "0.7726978649989217\n",
      "attack if dst_bytes > 0 else normal\n",
      "attack if proto == tcp else normal\n",
      "attack if src_pkts == 4 else normal\n",
      "attack if dst_ip_bytes > 0 else normal\n",
      "attack if dns_query == - else normal\n",
      "0.7687828251201123\n",
      "0.8748254002363812\n",
      "attack if conn_state == SF else normal\n",
      "attack if proto == tcp else normal\n",
      "attack if src_port != 5355 else normal\n",
      "attack if dst_ip_bytes > 0 else normal\n",
      "attack if dns_query == - else normal\n",
      "0.7503444799534564\n",
      "0.7300795554994317\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Evaluate generated rules\n",
    "################################################################################\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "from statistics import mode\n",
    "\n",
    "operations = {'<': operator.lt, '>': operator.gt, '==': operator.eq, '<=': operator.le, '>=': operator.ge, '!=': operator.ne}\n",
    "\n",
    "def evaluate_rules(tool_calls):\n",
    "    datasets = {\"normal\": normal_df_test, \"attack\": attack_df_test}\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for attack_type, dataset in datasets.items():\n",
    "        test_set_size = dataset.shape[0]\n",
    "        for i in tqdm(range(test_set_size), ncols=100, desc=f\"Predicting {attack_type} entries...\", disable=not show_progress):\n",
    "            predicted_attack_types = []\n",
    "            for tool_call in tool_calls:\n",
    "                args = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "                op = args[\"op\"]\n",
    "                feature_name = args[\"feature_name\"]\n",
    "                value = args[\"value\"]\n",
    "                try:\n",
    "                    value = float(value)\n",
    "                except ValueError:\n",
    "                    value\n",
    "                predicted_attack_types.append(\"attack\" if operations[op](dataset.iloc[i][feature_name], value) else \"normal\")\n",
    "            y_true.append(attack_type)\n",
    "            y_pred.append(mode(predicted_attack_types))\n",
    "    c_report = classification_report(y_true, y_pred, digits=4, output_dict=True)\n",
    "    c_matrix = confusion_matrix(y_true, y_pred)\n",
    "    # print(c_report)\n",
    "    # print(c_matrix)\n",
    "    return c_report\n",
    "\n",
    "# tool_calls = state[\"msgs\"][-7].additional_kwargs[\"tool_calls\"]\n",
    "# for tool_call in tool_calls:\n",
    "#     rule = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "#     print(\"attack if\", rule[\"feature_name\"], rule[\"op\"], rule[\"value\"], \"else normal\")\n",
    "\n",
    "# evaluate_rules(tool_calls)\n",
    "\n",
    "# test_f1_scores = []\n",
    "# for i in range(20, 0, -1):\n",
    "#     index = -7 * i\n",
    "#     tool_calls = state[\"msgs\"][index].additional_kwargs[\"tool_calls\"]\n",
    "#     for tool_call in tool_calls:\n",
    "#         rule = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "#     test_f1_scores.append(evaluate_rules(tool_calls)['macro avg']['f1-score'])\n",
    "\n",
    "# print(test_f1_scores)\n",
    "\n",
    "for i in range(len(state[\"msgs\"])):\n",
    "    if state[\"msgs\"][i].type != \"ai\":\n",
    "        continue\n",
    "    tool_calls = state[\"msgs\"][i].additional_kwargs[\"tool_calls\"]\n",
    "    for tool_call in tool_calls:\n",
    "        rule = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "        print(\"attack if\", rule[\"feature_name\"], rule[\"op\"], rule[\"value\"], \"else normal\")\n",
    "    c_report = evaluate_rules(tool_calls)\n",
    "    print(c_report[\"macro avg\"][\"f1-score\"])\n",
    "    print(c_report[\"attack\"][\"precision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT time taken: 0.00033612308502197266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9996    0.9999    0.9998      8408\n",
      "           1     0.9999    0.9997    0.9998     11592\n",
      "\n",
      "    accuracy                         0.9998     20000\n",
      "   macro avg     0.9998    0.9998    0.9998     20000\n",
      "weighted avg     0.9998    0.9998    0.9998     20000\n",
      "\n",
      "[[ 8407     1]\n",
      " [    3 11589]]\n",
      "\n",
      "\n",
      "RF time taken: 0.0036594917893409728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    1.0000    0.9999      8408\n",
      "           1     1.0000    0.9999    1.0000     11592\n",
      "\n",
      "    accuracy                         1.0000     20000\n",
      "   macro avg     0.9999    1.0000    0.9999     20000\n",
      "weighted avg     1.0000    1.0000    1.0000     20000\n",
      "\n",
      "[[ 8408     0]\n",
      " [    1 11591]]\n",
      "\n",
      "\n",
      "LLM time taken: 0.0002504175901412964\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack     0.0000    0.0000    0.0000     11592\n",
      "      normal     0.4204    1.0000    0.5919      8408\n",
      "\n",
      "    accuracy                         0.4204     20000\n",
      "   macro avg     0.2102    0.5000    0.2960     20000\n",
      "weighted avg     0.1767    0.4204    0.2489     20000\n",
      "\n",
      "[[    0 11592]\n",
      " [    0  8408]]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Evaluate generated rules for efficiency\n",
    "################################################################################\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tabulate import tabulate\n",
    "from statistics import mode\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sample_size = 100000\n",
    "\n",
    "# Load dateset\n",
    "df = pd.read_csv(os.getcwd() + f'/data/sample-{sample_size}-2.csv')\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Split dataset according to attack type\n",
    "normal_df = df[df['label'] == 0]\n",
    "attack_df = df[df['label'] == 1]\n",
    "\n",
    "# Split dataset into training and test set\n",
    "normal_df_train = normal_df.sample(frac=0.8, random_state=42)\n",
    "normal_df_test = normal_df.drop(normal_df_train.index)\n",
    "attack_df_train = attack_df.sample(frac=0.8, random_state=42)\n",
    "attack_df_test = attack_df.drop(attack_df_train.index)\n",
    "\n",
    "X_train = pd.concat([normal_df_train, attack_df_train]).drop(columns=['label', 'type'])\n",
    "y_train = pd.concat([normal_df_train, attack_df_train])['label']\n",
    "X_test = pd.concat([normal_df_test, attack_df_test]).drop(columns=['label', 'type'])\n",
    "y_test = pd.concat([normal_df_test, attack_df_test])['label']\n",
    "\n",
    "# Create instances of ML models\n",
    "model_dt = DecisionTreeClassifier()\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "# Fit the models to the training data\n",
    "model_dt.fit(X_train, y_train)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_true = y_test\n",
    "\n",
    "elapsed_times_dt = []\n",
    "elapsed_times_rf = []\n",
    "elapsed_times_llm = []\n",
    "y_pred_dt = []\n",
    "y_pred_rf = []\n",
    "y_pred_llm = []\n",
    "for i in range(len(X_test)):\n",
    "    # Predict using DT\n",
    "    start = time.time()\n",
    "    y_pred_dt.append(model_dt.predict([X_test.iloc[i]]))\n",
    "    end = time.time()\n",
    "    elapsed_times_dt.append(end - start)\n",
    "\n",
    "    # Predict using RF\n",
    "    start = time.time()\n",
    "    y_pred_rf.append(model_rf.predict([X_test.iloc[i]]))\n",
    "    end = time.time()\n",
    "    elapsed_times_rf.append(end - start)\n",
    "\n",
    "    # Predict using LLM\n",
    "    start = time.time()\n",
    "    row = X_test.iloc[i]\n",
    "    # conditions = [\n",
    "    #     row['proto'] == \"tcp\",\n",
    "    #     row['service'] == \"-\",\n",
    "    #     row['src_ip'] == \"192.168.1.31\",\n",
    "    #     row['dst_ip'] != \"224.0.0.252\",\n",
    "    #     row['dst_port'] == 80\n",
    "    # ]\n",
    "    conditions = [\n",
    "        row['proto'] == \"tcp\",\n",
    "        row['service'] == \"-\",\n",
    "        row['src_ip'] == \"192.168.1.31\",\n",
    "        row['dst_port'] == \"80\",\n",
    "        row['dns_query'] == \"-\"\n",
    "    ]\n",
    "    predicted_attack_types = [\"attack\" if condition else \"normal\" for condition in conditions]\n",
    "    y_pred_llm.append(mode(predicted_attack_types))\n",
    "    end = time.time()\n",
    "    elapsed_times_llm.append(end - start)\n",
    "\n",
    "print(f\"DT time taken: {sum(elapsed_times_dt)/len(X_test)}\")\n",
    "print(classification_report(y_true, y_pred_dt, digits=4, output_dict=False))\n",
    "print(confusion_matrix(y_true, y_pred_dt))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"RF time taken: {sum(elapsed_times_rf)/len(X_test)}\")\n",
    "print(classification_report(y_true, y_pred_rf, digits=4, output_dict=False))\n",
    "print(confusion_matrix(y_true, y_pred_rf))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"LLM time taken: {sum(elapsed_times_llm)/len(X_test)}\\n\")\n",
    "print(classification_report([\"attack\" if y else \"normal\" for y in y_true], y_pred_llm, digits=4, output_dict=False))\n",
    "print(confusion_matrix([\"attack\" if y else \"normal\" for y in y_true], y_pred_llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'normal',\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S4025371\\OneDrive - RMIT University\\Repositories\\iot-llm\\.conda\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"proto\": \"if proto == 'udp' then normal else attack\",\n",
      "  \"service\": \"if service == 'dns' then normal else attack\",\n",
      "  \"conn_state\": \"if conn_state == 'S0' then normal else attack\",\n",
      "  \"src_bytes\": \"if src_bytes == 66 then normal else attack\",\n",
      "  \"dst_bytes\": \"if dst_bytes == 0 then normal else attack\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Generate Rules\n",
    "################################################################################\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "dotenv.load_dotenv(os.getcwd() + '/../.env')\n",
    "\n",
    "template = \"\"\"\n",
    "You are provided with network data entries categorized as either normal or attack, along with their corresponding feature names.\n",
    "Carefully analyze the differences between normal and attack entries by comparing corresponding fields.\n",
    "Generate 5 simple and deterministic rules for top 5 important features to filter an entry as either normal or attack. \n",
    "Output only in the JSON format with the structure: \n",
    "{{'feature1': 'rule', 'feature2': 'rule', ..., 'feature5': 'rule'}}.\n",
    "\n",
    "Feature Names:\n",
    "```{feature_names}```\n",
    "\n",
    "Normal Entries:\n",
    "```{normal_entries}```\n",
    "\n",
    "Attack Entries:\n",
    "```{attack_entries}```\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"feature_names\", \"normal_entries\", \"attack_entries\"])\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "model_name = \"gpt-4o\"\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.0)\n",
    "# model_name = \"gemini-1.5-pro\"\n",
    "# llm = ChatAnthropic(model='claude-3-opus-20240229')\n",
    "# model_name = \"claude-3-opus-20240229\"\n",
    "chain = prompt | llm\n",
    "train_set_size = sample_size\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"ton-iot\",\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "\n",
    "normal_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'normal'})['embeddings']\n",
    "normal_mean_vector = np.mean(normal_vectors, axis=0).tolist()\n",
    "normal_documents = vector_store._collection.query(query_embeddings=[normal_mean_vector], n_results=10)['documents'][0]\n",
    "\n",
    "attack_vectors = vector_store._collection.get(include=['embeddings'], where={'label': 'attack'})['embeddings']\n",
    "attack_mean_vector = np.mean(attack_vectors, axis=0).tolist()\n",
    "attack_documents = vector_store._collection.query(query_embeddings=[attack_mean_vector], n_results=10)['documents'][0]\n",
    "\n",
    "completion = chain.invoke({\n",
    "    \"feature_names\": normal_df_train.columns.to_list(),\n",
    "    \"normal_entries\": \",\\n\".join([f\"{doc} --> normal\" for doc in normal_documents]),\n",
    "    \"attack_entries\": \",\\n\".join([f\"{doc} --> attack\" for doc in attack_documents])\n",
    "    })\n",
    "\n",
    "print(completion.content)\n",
    "\n",
    "with open(f\"results/generated-rules-{sample_size}-llm-{model_name}.txt\", \"a\") as f:\n",
    "    f.write(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting normal entries...: 100%|███████████████████████████| 1000/1000 [00:00<00:00, 3019.36it/s]\n",
      "Predicting attack entries...: 100%|███████████████████████████| 1000/1000 [00:00<00:00, 3651.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack       0.65      1.00      0.79      1000\n",
      "      normal       1.00      0.47      0.64      1000\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.82      0.73      0.72      2000\n",
      "weighted avg       0.82      0.73      0.72      2000\n",
      "\n",
      "[[998   2]\n",
      " [528 472]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Evaluate generated rules\n",
    "################################################################################\n",
    "\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "datasets = {\"normal\": normal_df_test, \"attack\": attack_df_test}\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for attack_type, dataset in datasets.items():\n",
    "    test_set_size = dataset.shape[0]\n",
    "    \n",
    "    for i in tqdm(range(test_set_size), ncols=100, desc=f\"Predicting {attack_type} entries...\"):\n",
    "        predicted_attack_types = []\n",
    "        # print((dataset.iloc[i]['conn_state']))\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['src_ip'] == \"192.168.1.195\" else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['src_port'] in range(52333, 60743) else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['dst_ip'] == \"224.0.0.252\" else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['dst_port'] == 5355 else \"attack\")\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['proto'] == \"udp\" else \"attack\")\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['service'] == \"dns\" else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['duration'] >= 0.001 else \"attack\")\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['src_bytes'] == 66 else \"attack\")\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['dst_bytes'] == 0 else \"attack\")\n",
    "        predicted_attack_types.append(\"normal\" if dataset.iloc[i]['conn_state'] in [\"S0\"] else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['dst_ip_bytes'] == 0 else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['src_ip_bytes'] == 122 else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['src_pkts'] == 2 else \"attack\")\n",
    "        # predicted_attack_types.append(\"normal\" if dataset.iloc[i]['dst_pkts'] == 0 else \"attack\")\n",
    "        y_true.append(attack_type)\n",
    "        y_pred.append(mode(predicted_attack_types))\n",
    "        # y_pred.append(\"normal\" if predicted_attack_types.count(\"normal\") > 0 else \"attack\")\n",
    "        # y_pred.append(\"attack\" if predicted_attack_types.count(\"attack\") > 0 else \"normal\")\n",
    "        # y_pred.append(\"normal\" if predicted_attack_types.count(\"normal\") == 5 else \"attack\")\n",
    "        # y_pred.append(\"normal\" if predicted_attack_types.count(\"normal\") == 5 else \"attack\")\n",
    "\n",
    "c_report = classification_report(y_true, y_pred)\n",
    "c_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "with open(f\"results/result-llm-{sample_size}-2.txt\", \"a\") as f:\n",
    "    f.write(f\"Classication Report\\n{c_report}\\n\\nConfusion Matrix\\n{c_matrix}\")\n",
    "\n",
    "print(c_report)\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/home/s4025371/anaconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Based on the provided data entries, we can see that normal entries have higher values for features such as flow duration, header length, rate, duration, and total size compared to attack entries. Additionally, normal entries have more occurrences of protocols like HTTP, HTTPS, DNS, SSH, TCP, UDP, DHCP, ARP, ICMP, and IPv.\\n\\nOn the other hand, attack entries have lower values for the mentioned features and do not have as many occurrences of the mentioned protocols. Attack entries also tend to have higher values for features like magnitude, radius, covariance, variance, and weight compared to normal entries.\\n\\nIn summary, normal entries exhibit higher network activity and a wider range of protocols, while attack entries show lower network activity and fewer protocol occurrences.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 149, 'prompt_tokens': 2787, 'total_tokens': 2936}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-93f0cf1f-2f0a-4937-95d9-da6e426ae510-0' usage_metadata={'input_tokens': 2787, 'output_tokens': 149, 'total_tokens': 2936}\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Get a Summary\n",
    "################################################################################\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tiktoken     # https://github.com/openai/tiktoken\n",
    "\n",
    "dotenv.load_dotenv(os.getcwd() + '/../.env')\n",
    "\n",
    "template = \"\"\"\n",
    "Given normal and attack network data entries, output human understandable small summary on \n",
    "how attack and normal entries can be simply separated.\n",
    "\n",
    "Feature Names:\n",
    "```{feature_names}```\n",
    "\n",
    "Normal Entries:\n",
    "```{normal_entries}```\n",
    "\n",
    "Attack Entries:\n",
    "```{attack_entries}```\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"feature_names\", \"normal_entries\", \"attack_entries\"])\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")\n",
    "chain = prompt | llm\n",
    "train_set_size = sample_size\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"ton-iot\",\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 5, \"fetch_k\": 5})\n",
    "normal_documents = retriever.invoke(str(normal_df_test.iloc[0].to_list()), filter={\"source\": \"ton-iot\", \"label\": \"normal\"})\n",
    "attack_documents = retriever.invoke(str(attack_df_test.iloc[0].to_list()), filter={\"source\": \"ton-iot\", \"label\": \"attack\"})\n",
    "completion = chain.invoke({\n",
    "    \"feature_names\": normal_df_train.columns.to_list(),\n",
    "    \"normal_entries\": \",\\n\".join([f\"{doc.page_content} --> {doc.metadata['label']}\" for doc in normal_documents]),\n",
    "    \"attack_entries\": \",\\n\".join([f\"{doc.page_content} --> {doc.metadata['label']}\" for doc in attack_documents])\n",
    "    })\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# \n",
    "################################################################################\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "template = \"\"\"\n",
    "Your task is to identify whether the query is attack or normal. Then \n",
    "generate a policy to filter the given query based on the values. \n",
    "You will be given feature names of the entries and similar entries along \n",
    "with the input query to make a decision.\n",
    "\n",
    "Feature Names:\n",
    "```{feature_names}```\n",
    "\n",
    "Similar Entries:\n",
    "```{similar_entries}```\n",
    "\n",
    "Input Query: \n",
    "```{query}```\n",
    "\n",
    "Policy:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"feature_names\", \"similar_entries\", \"query\"])\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")\n",
    "chain = prompt | llm\n",
    "train_set_size = sample_size\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"ton-iot\",\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=f\"./vector-stores/chroma-db-{train_set_size}-2\")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 5, \"fetch_k\": 5})\n",
    "query_document = str(normal_df_test.iloc[5].to_list())\n",
    "similar_documents = retriever.invoke(query_document, filter={\"source\": \"ton-iot\"})\n",
    "chain.invoke({\n",
    "    \"feature_names\": normal_df_train.columns.to_list(),\n",
    "    \"similar_entries\": \",\\n\".join([f\"{doc.page_content} --> {doc.metadata['label']}\" for doc in similar_documents]),\n",
    "    \"query\": query_document\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens: 2780\n"
     ]
    }
   ],
   "source": [
    "# print(completion.text)\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "num_tokens = len(encoding.encode(str(completion.text)))\n",
    "print(\"Num tokens:\", num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
