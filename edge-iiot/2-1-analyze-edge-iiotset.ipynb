{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load json dataset from json\n",
    "with open('edge-iiotset-ddos-test.json', 'r') as f:\n",
    "    ddos_json_test = json.load(f)\n",
    "\n",
    "with open('edge-iiotset-normal-test.json', 'r') as f:\n",
    "    normal_json_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"all-minilm\")\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"edge-iiotset\",\n",
    "    embedding_function=embeddings, \n",
    "    persist_directory=\"./chroma_langchain_db\")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 5, \"fetch_k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test ddos samples: 100%|██████████████████████████████████████| 9879/9879 [2:13:54<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      9879\n",
      "\n",
      "    accuracy                           1.00      9879\n",
      "   macro avg       1.00      1.00      1.00      9879\n",
      "weighted avg       1.00      1.00      1.00      9879\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample_size = len(ddos_json_test)\n",
    "# sample_size = 100\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in tqdm(range(sample_size), ncols=100, desc=\"Test ddos samples\"):\n",
    "    query_document = ddos_json_test[i]\n",
    "    similar_documents = retriever.invoke(query_document, filter={\"source\": \"edge-iiotset\"})\n",
    "    y_true.append(1)\n",
    "    if mode([doc.metadata[\"label\"] for doc in similar_documents]) == \"ddos\":\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test normal samples: 100%|██████████████████████████████████████| 4860/4860 [38:49<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.63      0.78      4860\n",
      "\n",
      "    accuracy                           0.63      4860\n",
      "   macro avg       0.50      0.32      0.39      4860\n",
      "weighted avg       1.00      0.63      0.78      4860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\S4025371\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\S4025371\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\S4025371\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sample_size = len(normal_json_test)\n",
    "# sample_size = 100\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in tqdm(range(sample_size), ncols=100, desc=\"Test normal samples\"):\n",
    "    query_document = normal_json_test[i]\n",
    "    similar_documents = retriever.invoke(query_document, filter={\"source\": \"edge-iiotset\"})\n",
    "    y_true.append(1)\n",
    "    if mode([doc.metadata[\"label\"] for doc in similar_documents]) == \"normal\":\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
