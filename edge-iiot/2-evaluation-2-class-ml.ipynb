{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  8000\n",
      "Test set size:  2000\n",
      "Index(['ip.src_host', 'ip.dst_host', 'arp.dst.proto_ipv4', 'arp.opcode',\n",
      "       'arp.hw.size', 'arp.src.proto_ipv4', 'icmp.checksum', 'icmp.seq_le',\n",
      "       'icmp.transmit_timestamp', 'http.file_data', 'http.content_length',\n",
      "       'http.request.uri.query', 'http.request.method', 'http.referer',\n",
      "       'http.request.full_uri', 'http.request.version', 'http.response',\n",
      "       'tcp.ack', 'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin',\n",
      "       'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack',\n",
      "       'tcp.dstport', 'tcp.flags', 'tcp.flags.ack', 'tcp.len', 'tcp.options',\n",
      "       'tcp.payload', 'tcp.seq', 'tcp.srcport', 'udp.port', 'udp.stream',\n",
      "       'udp.time_delta', 'dns.qry.name', 'dns.qry.name.len', 'dns.qry.qu',\n",
      "       'dns.retransmission', 'dns.retransmit_request', 'mqtt.conack.flags',\n",
      "       'mqtt.conflag.cleansess', 'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len',\n",
      "       'mqtt.msg', 'mqtt.msgtype', 'mqtt.proto_len', 'mqtt.protoname',\n",
      "       'mqtt.topic', 'mqtt.topic_len', 'mqtt.ver'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Load dataset and split it into training and test set\n",
    "################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "# Load dateset\n",
    "df = pd.read_csv(os.getcwd() + f'/data/sample-{sample_size}-2.csv')\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Split dataset according to attack type\n",
    "normal_df = df[df['Attack_label'] == 0]\n",
    "attack_df = df[df['Attack_label'] == 1]\n",
    "\n",
    "# Split dataset into training and test set\n",
    "normal_df_train = normal_df.sample(frac=0.8, random_state=42)\n",
    "normal_df_test = normal_df.drop(normal_df_train.index)\n",
    "attack_df_train = attack_df.sample(frac=0.8, random_state=42)\n",
    "attack_df_test = attack_df.drop(attack_df_train.index)\n",
    "\n",
    "X_train = pd.concat([normal_df_train, attack_df_train]).drop(columns=['frame.time', 'Attack_label', 'Attack_type'])\n",
    "y_train = pd.concat([normal_df_train, attack_df_train])['Attack_label']\n",
    "X_test = pd.concat([normal_df_test, attack_df_test]).drop(columns=['frame.time', 'Attack_label', 'Attack_type'])\n",
    "y_test = pd.concat([normal_df_test, attack_df_test])['Attack_label']\n",
    "\n",
    "print(\"Training set size: \", X_train.shape[0])\n",
    "print(\"Test set size: \", X_test.shape[0])\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "[[1000    0]\n",
      " [   0 1000]]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Predict from Decision Tree model\n",
    "################################################################################\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_true = y_test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "c_report = classification_report(y_true, y_pred)\n",
    "c_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "with open(f\"results/result-dt-{sample_size}-2.txt\", \"w\") as f:\n",
    "    f.write(f\"Classication Report\\n{c_report}\\n\\nConfusion Matrix\\n{c_matrix}\")\n",
    "\n",
    "print(c_report)\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dns.qry.name.len', 0.9979026217228476), ('mqtt.msg', 0.0004244694132334541), ('dns.retransmission', 0.00039950062421972144), ('mqtt.conack.flags', 0.00034956304619225624), ('mqtt.topic', 0.0003245942571785236)]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Feature Importance - Decision Tree \n",
    "################################################################################\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "n = 100\n",
    "\n",
    "feature_importances = {}\n",
    "for i in range(n):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    sorted_features = sorted(zip(model.feature_importances_, model.feature_names_in_), reverse=True)\n",
    "    for importance, name in sorted_features:\n",
    "        if name in feature_importances:\n",
    "            feature_importances[name].append(importance)\n",
    "        else:\n",
    "            feature_importances[name] = [importance]\n",
    "\n",
    "average_feature_importances = {}\n",
    "for name, importances in feature_importances.items():\n",
    "    average_feature_importances[name] = sum(importances) / len(importances)\n",
    "\n",
    "top_features = sorted(average_feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "with open(f\"results/feature-importance-{sample_size}-dt.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\".join([str(feature) for feature in top_features[:5]]))\n",
    "\n",
    "print(top_features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "[[1000    0]\n",
      " [   0 1000]]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Predict from Random Forest model\n",
    "################################################################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_true = y_test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "c_report = classification_report(y_true, y_pred)\n",
    "c_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "with open(f\"results/result-rf-{sample_size}-2.txt\", \"w\") as f:\n",
    "    f.write(f\"Classication Report\\n{c_report}\\n\\nConfusion Matrix\\n{c_matrix}\")\n",
    "\n",
    "print(c_report)\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Feature Importance - Random Forest\n",
    "################################################################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n = 100\n",
    "\n",
    "feature_importances = {}\n",
    "for i in range(n):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    sorted_features = sorted(zip(model.feature_importances_, model.feature_names_in_), reverse=True)\n",
    "    for importance, name in sorted_features:\n",
    "        if name in feature_importances:\n",
    "            feature_importances[name].append(importance)\n",
    "        else:\n",
    "            feature_importances[name] = [importance]\n",
    "\n",
    "average_feature_importances = {}\n",
    "for name, importances in feature_importances.items():\n",
    "    average_feature_importances[name] = sum(importances) / len(importances)\n",
    "\n",
    "top_features = sorted(average_feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "with open(f\"results/feature-importance-{sample_size}-rf.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\".join([str(feature) for feature in top_features[:5]]))\n",
    "\n",
    "print(top_features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        10\n",
      "           1       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.71      0.70      0.70        20\n",
      "weighted avg       0.71      0.70      0.70        20\n",
      "\n",
      "[[8 2]\n",
      " [4 6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S4025371\\OneDrive - RMIT University\\Repositories\\iot-llm\\.conda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Predict from Logistic Regression model\n",
    "################################################################################\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_true = y_test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "c_report = classification_report(y_true, y_pred)\n",
    "c_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "with open(f\"results/result-lr-{sample_size}-2.txt\", \"w\") as f:\n",
    "    f.write(f\"Classication Report\\n{c_report}\\n\\nConfusion Matrix\\n{c_matrix}\")\n",
    "\n",
    "print(c_report)\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.56        10\n",
      "           1       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.60      0.60      0.60        20\n",
      "weighted avg       0.60      0.60      0.60        20\n",
      "\n",
      "[[5 5]\n",
      " [3 7]]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Predict from SVM model\n",
    "################################################################################\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier model\n",
    "model = SVC()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_true = y_test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "c_report = classification_report(y_true, y_pred)\n",
    "c_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "with open(f\"results/result-svm-{sample_size}-2.txt\", \"w\") as f:\n",
    "    f.write(f\"Classication Report\\n{c_report}\\n\\nConfusion Matrix\\n{c_matrix}\")\n",
    "\n",
    "print(c_report)\n",
    "print(c_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
